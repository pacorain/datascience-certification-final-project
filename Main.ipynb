{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Scoring Job Relocation Opportunities - Playground Notebook\n",
    "\n",
    "Austin Rainwater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade sqlalchemy pymysql\n",
    "\n",
    "from urllib.parse import quote as url_encode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import requests\n",
    "import xml.etree.ElementTree as xml\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "split_executor = ThreadPoolExecutor(max_workers=10)\n",
    "\n",
    "from pandas import json_normalize\n",
    "from itertools import product\n",
    "\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    Table,\n",
    "    Column,\n",
    "    MetaData,\n",
    "    String,\n",
    "    Numeric,\n",
    "    Integer\n",
    ")\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open('secrets.yaml', 'r') as secrets_file:\n",
    "    secrets = yaml.safe_load(secrets_file)\n",
    "    \n",
    "header = {\"User-Agent\": \n",
    "          'datascience jupyter notebook/0.0 '\n",
    "          '(https://github.com/pacorain/datascience-certification-final-project; '\n",
    "          'Austin Rainwater, paco@heckin.io)'}\n",
    "v = '20201108'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Definition\n",
    "\n",
    "Obviously, a good place for me to start is with some cities. Below is the table definition for the cities I will be exploring and their specific traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 23:25:19,348 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-11-23 23:25:19,350 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,359 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-11-23 23:25:19,360 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,368 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-11-23 23:25:19,369 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,381 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-11-23 23:25:19,382 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,388 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-11-23 23:25:19,389 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,392 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-11-23 23:25:19,393 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,396 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-11-23 23:25:19,397 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,403 INFO sqlalchemy.engine.base.Engine DESCRIBE `city`\n",
      "2020-11-23 23:25:19,404 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,415 INFO sqlalchemy.engine.base.Engine ROLLBACK\n",
      "2020-11-23 23:25:19,419 INFO sqlalchemy.engine.base.Engine DESCRIBE `city`\n",
      "2020-11-23 23:25:19,420 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,424 INFO sqlalchemy.engine.base.Engine ROLLBACK\n",
      "2020-11-23 23:25:19,428 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE city (\n",
      "\tcity_name VARCHAR(50) NOT NULL COMMENT 'Community Name', \n",
      "\tmetro_name VARCHAR(50) COMMENT 'Metropolitan Area Name', \n",
      "\tstate VARCHAR(2) NOT NULL COMMENT '2-Letter abbreviation of State', \n",
      "\tlat NUMERIC(10, 6) NOT NULL COMMENT 'Latitude of City', \n",
      "\tlng NUMERIC(10, 6) NOT NULL COMMENT 'Longitude of City', \n",
      "\tarea_val NUMERIC(10, 4) NOT NULL COMMENT 'Area of city in square miles', \n",
      "\ttotal_pop INTEGER NOT NULL COMMENT 'Total population of city', \n",
      "\tPRIMARY KEY (city_name)\n",
      ")\n",
      "\n",
      "\n",
      "2020-11-23 23:25:19,429 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-11-23 23:25:19,501 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(secrets['db_connection_string'], echo=True)\n",
    "\n",
    "meta = MetaData()\n",
    "\n",
    "cities = Table(\n",
    "    'city', meta,\n",
    "    Column('city_name', String(50), primary_key=True, comment='Community Name'),\n",
    "    Column('metro_name', String(50), comment='Metropolitan Area Name'),\n",
    "    Column('state', String(2), nullable=False, comment='2-Letter abbreviation of State'),\n",
    "    Column('lat', Numeric(10, 6), nullable=False, comment='Latitude of City'),\n",
    "    Column('lng', Numeric(10, 6), nullable=False, comment='Longitude of City'),\n",
    "    Column('area_val', Numeric(10, 4), nullable=False, comment='Area of city in square miles'),\n",
    "    Column('total_pop', Integer, nullable=False, comment='Total population of city')\n",
    ")\n",
    "\n",
    "meta.drop_all(engine)\n",
    "meta.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with my birthplace: Fort Wayne, Indiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 23:25:26,045 INFO sqlalchemy.engine.base.Engine INSERT INTO city (city_name, metro_name, state) VALUES (%(city_name)s, %(metro_name)s, %(state)s)\n",
      "2020-11-23 23:25:26,046 INFO sqlalchemy.engine.base.Engine {'city_name': 'Fort Wayne', 'metro_name': 'Fort Wayne', 'state': 'IN'}\n",
      "2020-11-23 23:25:26,050 INFO sqlalchemy.engine.base.Engine ROLLBACK\n",
      "Oops! That didn't work.\n"
     ]
    }
   ],
   "source": [
    "new_city = cities.insert()\n",
    "\n",
    "try:\n",
    "    engine.execute(new_city, [\n",
    "        {'city_name': 'Fort Wayne', 'metro_name': 'Fort Wayne', 'state': 'IN'}\n",
    "    ])\n",
    "except:\n",
    "    print(\"Oops! That didn't work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, the table requires some more data to be able to insert the record. I could use the geocoder library from before to get the latitude and longitude, but since I will be using Wikipedia anyway, let's see if I can grab it from there.\n",
    "\n",
    "I did some experimenting with the [Wikipedia API Sandbox](https://en.wikipedia.org/wiki/Special:ApiSandbox#action=parse&format=json&page=Fort%20Wayne%2C%20Indiana&redirects=1&prop=wikitext), and oddly enough while there are multiple endpoints capable of getting the _names_ of the templates used in a page, I could not for the life of me find a way to get the _data inserted to_ the templates in an easy format such as JSON. So instead, I'm going to grab the `parsetree` and parse it with Python's XML libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'Fort Wayne'\n",
    "state_name = 'IN'\n",
    "\n",
    "wikipedia_url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "    \"action\": \"parse\",\n",
    "    \"format\": \"json\",\n",
    "    \"redirects\": \"1\",\n",
    "    \"page\": f\"{city_name}, {state_name}\",\n",
    "    \"prop\": \"parsetree\"\n",
    "}\n",
    "\n",
    "response = requests.get(wikipedia_url, params=params, headers=header).json()['parse']['parsetree']['*']\n",
    "response = xml.canonicalize(response, strip_text=True)\n",
    "\n",
    "# Write XML data for local exploration\n",
    "with open('data/fort_wayne.xml', 'w') as xml_file:\n",
    "    xml_file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, going through the XML file, the map on the Wikipedia article is an SVG (i.e. an image, not something that contains computer-readable geographic data), so I will need to use a geocoder. \n",
    "\n",
    "I recall from the previous lab that when you grab data from Foursquare's API, it will geocode the 'near' parameter and return the latitude and logitude used.\n",
    "\n",
    "I also want to include the total size of the city, so in order to enter data into the table, I need to grab data from Wikipedia _and_ Foursquare. Which is fine, because I need more data to explore possible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data = xml.fromstring(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare_url = \"https://api.foursquare.com/v2/venues/explore\"\n",
    "\n",
    "params = {\n",
    "    'client_id': secrets['4SQ_CLIENT_ID'],\n",
    "    'client_secret': secrets['4SQ_CLIENT_SECRET'],\n",
    "    'limit': '50',\n",
    "    'v': v,\n",
    "    'near': 'Fort Wayne, IN',\n",
    "    'radius': 1000,\n",
    "    'time': 'any', \n",
    "    'day': 'any',\n",
    "    'sortByPopularity': '1'\n",
    "}\n",
    "\n",
    "foursquare_response = requests.get(foursquare_url, params=params, headers=header).json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.1306"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def template_value(wiki_data, template_title, part_name):\n",
    "    template = wiki_data.find(\".//template[title='{}']\".format(template_title))\n",
    "    return template.find(\".part[name='{}'].value\".format(part_name)).text\n",
    "\n",
    "lat = float(foursquare_response['geocode']['center']['lat'])\n",
    "lng = float(foursquare_response['geocode']['center']['lng'])\n",
    "sq_mi = float(template_value(wiki_data, \"Infobox settlement\", \"area_total_sq_mi\"))\n",
    "total_pop = int(template_value(wiki_data, \"Infobox settlement\", \"population_est\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, I've gotten the values I need initially for a city; now let's try inserting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 23:25:29,737 INFO sqlalchemy.engine.base.Engine INSERT INTO city (city_name, metro_name, state, lat, lng, area_val, total_pop) VALUES (%(city_name)s, %(metro_name)s, %(state)s, %(lat)s, %(lng)s, %(area_val)s, %(total_pop)s)\n",
      "2020-11-23 23:25:29,738 INFO sqlalchemy.engine.base.Engine {'city_name': 'Fort Wayne', 'metro_name': 'Fort Wayne', 'state': 'IN', 'lat': 41.1306, 'lng': -85.12886, 'area_val': 110.79, 'total_pop': 270402}\n",
      "2020-11-23 23:25:29,742 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7f69cc6e6f70>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(new_city, [{\n",
    "    'city_name': 'Fort Wayne', \n",
    "    'metro_name': 'Fort Wayne', \n",
    "    'state': 'IN', \n",
    "    'lat': lat,\n",
    "    'lng': lng,\n",
    "    'area_val': sq_mi,\n",
    "    'total_pop': total_pop\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 23:39:42,785 INFO sqlalchemy.engine.base.OptionEngine SELECT city.city_name, city.metro_name, city.state, city.lat, city.lng, city.area_val, city.total_pop \n",
      "FROM city\n",
      "2020-11-23 23:39:42,786 INFO sqlalchemy.engine.base.OptionEngine {}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>area_val</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fort Wayne</td>\n",
       "      <td>Fort Wayne</td>\n",
       "      <td>IN</td>\n",
       "      <td>41.1306</td>\n",
       "      <td>-85.12886</td>\n",
       "      <td>110.79</td>\n",
       "      <td>270402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city_name  metro_name state      lat       lng  area_val  total_pop\n",
       "0  Fort Wayne  Fort Wayne    IN  41.1306 -85.12886    110.79     270402"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = cities.select()\n",
    "\n",
    "pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. \n",
    "\n",
    "Next, I want to grab some data from Foursquare to build a feature based on what's popular within 1, 5, 25, and 100 km. I'll use the category hierarchy like I did in the week 3 lab. Given that the Foursquare API allows for 99,500 of these calls a day, and up to 5,000 per hour, I can also do this comfortably with each section defined in the `venues/explore` enpoint to see how much variety is in each section in an area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.foursquare.com/v2/venues/categories'\n",
    "params = {\n",
    "    'client_id': secrets['4SQ_CLIENT_ID'],\n",
    "    'client_secret': secrets['4SQ_CLIENT_SECRET'],\n",
    "    'v': v\n",
    "}\n",
    "foursquare_categories = requests.get(url, params=params).json()\n",
    "\n",
    "def category_hier(categories, prefix=[]):\n",
    "    result = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category = json_normalize(category).iloc[0]\n",
    "        current_category = pd.Series(\n",
    "            data=prefix + [category.shortName] + [np.nan] * (4 - len(prefix)),\n",
    "            name=str(category.id),\n",
    "            index=[\n",
    "                'cat_level_1',\n",
    "                'cat_level_2',\n",
    "                'cat_level_3',\n",
    "                'cat_level_4',\n",
    "                'cat_level_5'\n",
    "            ]\n",
    "        )\n",
    "        result.append(current_category)\n",
    "        if subcategories := category.categories:\n",
    "            result += category_hier(subcategories, prefix + [category.shortName])\n",
    "            \n",
    "    return result\n",
    "\n",
    "categories = foursquare_categories['response']['categories']\n",
    "category_df = pd.DataFrame(category_hier(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-e809ba68db51>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e809ba68db51>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    with aiohttp.ClientSession() as session for r, s in product(radii, sections):\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "radii = [1000, 5000, 25000, 100000]\n",
    "sections = ['food', 'drinks', 'coffee', 'shops', 'arts', 'outdoors', 'sights', 'trending', 'topPicks']\n",
    "\n",
    "async def get_popular_spots(city):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for r, s in product(radii, sections):\n",
    "            task = query_places(session, city, r, s)\n",
    "            tasks.append(task)\n",
    "        results = asyncio.gather(*tasks)\n",
    "    return pd.concat(results)\n",
    "    \n",
    "    \n",
    "async def query_places(session, location, radius, section):\n",
    "    url = \"https://api.foursquare.com/v2/venues/explore\"\n",
    "    params = {\n",
    "        'client_id': secrets['4SQ_CLIENT_ID'],\n",
    "        'client_secret': secrets['4SQ_CLIENT_SECRET'],\n",
    "        'limit': '50',\n",
    "        'v': v,\n",
    "        'near': location,\n",
    "        'radius': radius, \n",
    "        'section': section\n",
    "    }\n",
    "    async with session.get(url, params=params) as result:\n",
    "        data = await result.json()\n",
    "        venues = json_normailze(data, ['groups', 'items'], sep='_')\n",
    "        geo = json_normailze(data['geocode']).loc[0] # json_normalize returns single-index df\n",
    "        geo.index = pd.Index(f'geo_{name}' for name in geo.index)\n",
    "        venues.loc[:, geo.index] = geo.values\n",
    "        venues['city'] = location\n",
    "        venues['radius'] = radius\n",
    "        venues['section'] = sections\n",
    "        return venues\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
